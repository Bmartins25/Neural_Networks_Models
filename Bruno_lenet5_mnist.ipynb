{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bmartins25/Redes_Neurais_Modelos/blob/main/Bruno_lenet5_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MzZPjeHmhYR",
        "outputId": "c94997f1-fe2c-4295-9d34-87df084db4a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting watermark\n",
            "  Downloading watermark-2.4.3-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (6.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (67.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.16.2)\n",
            "Collecting jedi>=0.16 (from ipython>=6.0->watermark)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.6)\n",
            "Installing collected packages: jedi, watermark\n",
            "Successfully installed jedi-0.19.0 watermark-2.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOzuY8Yvj5wb",
        "outputId": "3760439d-cefa-45d0-de6f-7315bf1956e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Bruno Bartolomeu\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "torch: 2.0.1+cu118\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -a 'Bruno Bartolomeu' -v -p torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkoGLH_Tj5wn"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ORj09gnrj5wp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6hghKPxj5w0"
      },
      "source": [
        "## Model Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NnT0sZIwj5wu"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Architecture\n",
        "NUM_FEATURES = 32*32\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Other\n",
        "DEVICE = \"cuda:0\" #alterar após erro (Passar de 3 para 0)\n",
        "GRAYSCALE = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RirLfgRIj8Go"
      },
      "source": [
        "### MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHbjBeooj8Gp",
        "outputId": "033a2e71-ffdf-4805-e896-80aa0004e037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([128, 1, 32, 32])\n",
            "Image label dimensions: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "##########################\n",
        "### MNIST DATASET\n",
        "##########################\n",
        "\n",
        "resize_transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "# Note transforms.ToTensor() scales input images\n",
        "# to 0-1 range\n",
        "train_dataset = datasets.MNIST(root='data',\n",
        "                               train=True,\n",
        "                               transform=resize_transform,\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='data',\n",
        "                              train=False,\n",
        "                              transform=resize_transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=False)\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JNXy1wEj8Gr",
        "outputId": "7fb172d5-c266-4a5e-9ae5-9a7811b804a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
            "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(DEVICE)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "for epoch in range(2):\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "\n",
        "        print('Epoch:', epoch+1, end='')\n",
        "        print(' | Batch index:', batch_idx, end='')\n",
        "        print(' | Batch size:', y.size()[0])\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OBYn1qCHj8Gs"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "### MODEL\n",
        "##########################\n",
        "\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, grayscale=False):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.grayscale = grayscale\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        if self.grayscale:\n",
        "            in_channels = 1\n",
        "        else:\n",
        "            in_channels = 3\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels, 6, kernel_size=5),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16*5*5, 120),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(84, num_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_lza9t_uj5w1"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(NUM_CLASSES, GRAYSCALE)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzh3ROmRj5w7",
        "outputId": "c3588796-47ed-41a6-a823-fce5d837a4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/010 | Batch 0000/0469 | Cost: 2.3056\n",
            "Epoch: 001/010 | Batch 0050/0469 | Cost: 0.5722\n",
            "Epoch: 001/010 | Batch 0100/0469 | Cost: 0.2986\n",
            "Epoch: 001/010 | Batch 0150/0469 | Cost: 0.2654\n",
            "Epoch: 001/010 | Batch 0200/0469 | Cost: 0.2659\n",
            "Epoch: 001/010 | Batch 0250/0469 | Cost: 0.1108\n",
            "Epoch: 001/010 | Batch 0300/0469 | Cost: 0.2026\n",
            "Epoch: 001/010 | Batch 0350/0469 | Cost: 0.1334\n",
            "Epoch: 001/010 | Batch 0400/0469 | Cost: 0.1607\n",
            "Epoch: 001/010 | Batch 0450/0469 | Cost: 0.0795\n",
            "Epoch: 001/010 | Train: 97.042%\n",
            "Time elapsed: 0.50 min\n",
            "Epoch: 002/010 | Batch 0000/0469 | Cost: 0.1571\n",
            "Epoch: 002/010 | Batch 0050/0469 | Cost: 0.0802\n",
            "Epoch: 002/010 | Batch 0100/0469 | Cost: 0.0452\n",
            "Epoch: 002/010 | Batch 0150/0469 | Cost: 0.0685\n",
            "Epoch: 002/010 | Batch 0200/0469 | Cost: 0.1666\n",
            "Epoch: 002/010 | Batch 0250/0469 | Cost: 0.1195\n",
            "Epoch: 002/010 | Batch 0300/0469 | Cost: 0.1153\n",
            "Epoch: 002/010 | Batch 0350/0469 | Cost: 0.0418\n",
            "Epoch: 002/010 | Batch 0400/0469 | Cost: 0.1261\n",
            "Epoch: 002/010 | Batch 0450/0469 | Cost: 0.0466\n",
            "Epoch: 002/010 | Train: 98.535%\n",
            "Time elapsed: 0.87 min\n",
            "Epoch: 003/010 | Batch 0000/0469 | Cost: 0.0078\n",
            "Epoch: 003/010 | Batch 0050/0469 | Cost: 0.0677\n",
            "Epoch: 003/010 | Batch 0100/0469 | Cost: 0.0739\n",
            "Epoch: 003/010 | Batch 0150/0469 | Cost: 0.0673\n",
            "Epoch: 003/010 | Batch 0200/0469 | Cost: 0.0922\n",
            "Epoch: 003/010 | Batch 0250/0469 | Cost: 0.0994\n",
            "Epoch: 003/010 | Batch 0300/0469 | Cost: 0.0311\n",
            "Epoch: 003/010 | Batch 0350/0469 | Cost: 0.0564\n",
            "Epoch: 003/010 | Batch 0400/0469 | Cost: 0.0497\n",
            "Epoch: 003/010 | Batch 0450/0469 | Cost: 0.0782\n",
            "Epoch: 003/010 | Train: 99.013%\n",
            "Time elapsed: 1.24 min\n",
            "Epoch: 004/010 | Batch 0000/0469 | Cost: 0.0429\n",
            "Epoch: 004/010 | Batch 0050/0469 | Cost: 0.0495\n",
            "Epoch: 004/010 | Batch 0100/0469 | Cost: 0.0653\n",
            "Epoch: 004/010 | Batch 0150/0469 | Cost: 0.0688\n",
            "Epoch: 004/010 | Batch 0200/0469 | Cost: 0.0801\n",
            "Epoch: 004/010 | Batch 0250/0469 | Cost: 0.0282\n",
            "Epoch: 004/010 | Batch 0300/0469 | Cost: 0.0632\n",
            "Epoch: 004/010 | Batch 0350/0469 | Cost: 0.0217\n",
            "Epoch: 004/010 | Batch 0400/0469 | Cost: 0.0210\n",
            "Epoch: 004/010 | Batch 0450/0469 | Cost: 0.0715\n",
            "Epoch: 004/010 | Train: 99.063%\n",
            "Time elapsed: 1.60 min\n",
            "Epoch: 005/010 | Batch 0000/0469 | Cost: 0.0228\n",
            "Epoch: 005/010 | Batch 0050/0469 | Cost: 0.0221\n",
            "Epoch: 005/010 | Batch 0100/0469 | Cost: 0.0087\n",
            "Epoch: 005/010 | Batch 0150/0469 | Cost: 0.0162\n",
            "Epoch: 005/010 | Batch 0200/0469 | Cost: 0.0325\n",
            "Epoch: 005/010 | Batch 0250/0469 | Cost: 0.0714\n",
            "Epoch: 005/010 | Batch 0300/0469 | Cost: 0.0072\n",
            "Epoch: 005/010 | Batch 0350/0469 | Cost: 0.0287\n",
            "Epoch: 005/010 | Batch 0400/0469 | Cost: 0.0191\n",
            "Epoch: 005/010 | Batch 0450/0469 | Cost: 0.0325\n",
            "Epoch: 005/010 | Train: 99.433%\n",
            "Time elapsed: 1.96 min\n",
            "Epoch: 006/010 | Batch 0000/0469 | Cost: 0.0145\n",
            "Epoch: 006/010 | Batch 0050/0469 | Cost: 0.0237\n",
            "Epoch: 006/010 | Batch 0100/0469 | Cost: 0.0618\n",
            "Epoch: 006/010 | Batch 0150/0469 | Cost: 0.0059\n",
            "Epoch: 006/010 | Batch 0200/0469 | Cost: 0.0014\n",
            "Epoch: 006/010 | Batch 0250/0469 | Cost: 0.0557\n",
            "Epoch: 006/010 | Batch 0300/0469 | Cost: 0.0224\n",
            "Epoch: 006/010 | Batch 0350/0469 | Cost: 0.0127\n",
            "Epoch: 006/010 | Batch 0400/0469 | Cost: 0.0287\n",
            "Epoch: 006/010 | Batch 0450/0469 | Cost: 0.0101\n",
            "Epoch: 006/010 | Train: 99.440%\n",
            "Time elapsed: 2.31 min\n",
            "Epoch: 007/010 | Batch 0000/0469 | Cost: 0.0335\n",
            "Epoch: 007/010 | Batch 0050/0469 | Cost: 0.0119\n",
            "Epoch: 007/010 | Batch 0100/0469 | Cost: 0.0066\n",
            "Epoch: 007/010 | Batch 0150/0469 | Cost: 0.0111\n",
            "Epoch: 007/010 | Batch 0200/0469 | Cost: 0.0125\n",
            "Epoch: 007/010 | Batch 0250/0469 | Cost: 0.0617\n",
            "Epoch: 007/010 | Batch 0300/0469 | Cost: 0.0153\n",
            "Epoch: 007/010 | Batch 0350/0469 | Cost: 0.0053\n",
            "Epoch: 007/010 | Batch 0400/0469 | Cost: 0.0123\n",
            "Epoch: 007/010 | Batch 0450/0469 | Cost: 0.0139\n",
            "Epoch: 007/010 | Train: 99.650%\n",
            "Time elapsed: 2.66 min\n",
            "Epoch: 008/010 | Batch 0000/0469 | Cost: 0.0192\n",
            "Epoch: 008/010 | Batch 0050/0469 | Cost: 0.0367\n",
            "Epoch: 008/010 | Batch 0100/0469 | Cost: 0.0143\n",
            "Epoch: 008/010 | Batch 0150/0469 | Cost: 0.0013\n",
            "Epoch: 008/010 | Batch 0200/0469 | Cost: 0.0059\n",
            "Epoch: 008/010 | Batch 0250/0469 | Cost: 0.0222\n",
            "Epoch: 008/010 | Batch 0300/0469 | Cost: 0.0044\n",
            "Epoch: 008/010 | Batch 0350/0469 | Cost: 0.0116\n",
            "Epoch: 008/010 | Batch 0400/0469 | Cost: 0.0078\n",
            "Epoch: 008/010 | Batch 0450/0469 | Cost: 0.0045\n",
            "Epoch: 008/010 | Train: 99.613%\n",
            "Time elapsed: 3.03 min\n",
            "Epoch: 009/010 | Batch 0000/0469 | Cost: 0.0032\n",
            "Epoch: 009/010 | Batch 0050/0469 | Cost: 0.0268\n",
            "Epoch: 009/010 | Batch 0100/0469 | Cost: 0.0026\n",
            "Epoch: 009/010 | Batch 0150/0469 | Cost: 0.0028\n",
            "Epoch: 009/010 | Batch 0200/0469 | Cost: 0.0078\n",
            "Epoch: 009/010 | Batch 0250/0469 | Cost: 0.0260\n",
            "Epoch: 009/010 | Batch 0300/0469 | Cost: 0.0116\n",
            "Epoch: 009/010 | Batch 0350/0469 | Cost: 0.0072\n",
            "Epoch: 009/010 | Batch 0400/0469 | Cost: 0.0055\n",
            "Epoch: 009/010 | Batch 0450/0469 | Cost: 0.0190\n",
            "Epoch: 009/010 | Train: 99.752%\n",
            "Time elapsed: 3.38 min\n",
            "Epoch: 010/010 | Batch 0000/0469 | Cost: 0.0031\n",
            "Epoch: 010/010 | Batch 0050/0469 | Cost: 0.0203\n",
            "Epoch: 010/010 | Batch 0100/0469 | Cost: 0.0022\n",
            "Epoch: 010/010 | Batch 0150/0469 | Cost: 0.0133\n",
            "Epoch: 010/010 | Batch 0200/0469 | Cost: 0.0024\n",
            "Epoch: 010/010 | Batch 0250/0469 | Cost: 0.0060\n",
            "Epoch: 010/010 | Batch 0300/0469 | Cost: 0.0028\n",
            "Epoch: 010/010 | Batch 0350/0469 | Cost: 0.0563\n",
            "Epoch: 010/010 | Batch 0400/0469 | Cost: 0.0064\n",
            "Epoch: 010/010 | Batch 0450/0469 | Cost: 0.0389\n",
            "Epoch: 010/010 | Train: 99.780%\n",
            "Time elapsed: 3.74 min\n",
            "Total Training Time: 3.74 min\n"
          ]
        }
      ],
      "source": [
        "def compute_accuracy(model, data_loader, device): #treinando dados\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        cost.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f'\n",
        "                   %(epoch+1, NUM_EPOCHS, batch_idx,\n",
        "                     len(train_loader), cost))\n",
        "\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False): # save memory during inference\n",
        "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
        "              epoch+1, NUM_EPOCHS,\n",
        "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
        "\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "\n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzQMWKq5j5xE",
        "outputId": "c1257186-dc4e-4f8b-f4e8-85eaafde889d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 98.86%\n"
          ]
        }
      ],
      "source": [
        "with torch.set_grad_enabled(False): # save memory during inference\n",
        "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "4qoGMD-Zj8Gy",
        "outputId": "c8768d85-a708-4abc-d16f-6421c3c584fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for batch_idx, (features, targets) in enumerate(test_loader):\n",
        "\n",
        "    features = features\n",
        "    targets = targets\n",
        "    break\n",
        "\n",
        "\n",
        "nhwc_img = np.transpose(features[0], axes=(1, 2, 0))\n",
        "nhw_img = np.squeeze(nhwc_img.numpy(), axis=2)\n",
        "plt.imshow(nhw_img, cmap='Greys');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-CJGE63j8Gz",
        "outputId": "e0f15c28-0051-42d6-e9b6-9ca6fcb7c6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability 7 99.99%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "logits, probas = model(features.to(device)[0, None])\n",
        "print('Probability 7 %.2f%%' % (probas[0][7]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysAVZJ75j8G0",
        "outputId": "26fb774d-c302-482a-8e8e-28898096293f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas     : 1.5.3\n",
            "torch      : 2.0.1+cu118\n",
            "matplotlib : 3.7.1\n",
            "PIL        : 9.4.0\n",
            "numpy      : 1.23.5\n",
            "torchvision: 0.15.2+cu118\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%watermark -iv"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "371px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}